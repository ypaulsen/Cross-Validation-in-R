---
author: "Y. Paulsen"  
title: "R Notebook"
output: html_notebook
---

The code here cross validates a random forest algorithm given a provided dataset named dat12_14 with a two factor 
outcome variable called loan_status and a user supplied set of parameters for tuning. It takes as input a grid of 
parameters for the `ranger` package in R. The `ranger` package builds random forest models and takes the parameters 
`mtry` and `numt` where `mtry` sets the number of features to include in each regression and `numt` sets the number 
of trees to include in each forest. The model itself can be replaced by e.g. tidymodels code in order to easily run 
the same crossvalidation code for any number of machine learning algorithms by simply adjusting the input parameters.   
   
I used the `yardstick` package for its functions `metrics()` and `roc_auc()` to help generate measures of accuracy in the 
output. This program outputs a list called `output` containing the supplied pairs of input parameters and the 
corresponding crossvalidation results for each. The results of the crossvalidation are the mean Accuracy, mean AUC, 
and mean Cohen's \(\kappa\). The user may chose the metric they prefer to work with given the analysis at hand.    
    
```{r message=FALSE, warning=FALSE}
library(ranger)
library(dplyr)
library(yardstick)
library(visdat)
```

Read in the data from github user ypaulsen. 

```{r}
dat12_14 <- read.csv("https://github.com/ypaulsen/Cross-Validation-in-R/raw/main/dat12_14a.csv") 
dat12_14$loan_status <- as.factor(dat12_14$loan_status) # Change outcome to factor  
```

First lets have a look at the data: 

```{r}
dplyr::glimpse(dat12_14)
```

Using the `visdat` package to look for missing data. This set is free of missing values.  

```{r}
visdat::vis_miss(dat12_14)
```

The next chunk starts the crossvalidation by setting up the number of subsets to use and generating the sequence of 
index numbers to split the dataset during the nested for loop in the next code chunk.  

```{r}
# Size of subsets and sequence for subsetting       

CV <- 10  # Number of subsets
dat <- dat12_14  # Set dataset for crossvalidation

test_l <- nrow(dat)%/%CV   
seq <- seq(from=0, to=10*test_l, by = test_l)
```

This code contains a nested for-loop that achieves a crossvalidation in the i loop where i is the number of subsets to
crossvalidate. It repeats that procedure in the j-loop where j is the number of sets of parameters in the grid of test
parameters assigned in the first two lines of the chunk.  

```{r}

mtry <- c(3, 4)
numt <- c(300, 200)

mean_kappa <- c()
mean_AUC <- c()
mean_Acc <- c()

output <- list()

for(j in 1:length(mtry)){

  test <- list()
  train <- list()
  pred_cv <- list()
  results <- list()
  metrics <- list()
  kappa <- c()
  Acc <- c()
  AUC <- c()

  output$mtry[j] <- mtry[j]
  output$numt[j] <- numt[j]

  for(i in 1:CV){
    test_rows <- seq[i]:seq[i+1]
    test[[i]] <- dat[test_rows,]
    train[[i]] <- dat[-test_rows,]
    ranger_lending_cv <- ranger(loan_status ~ ., data = train[[i]], 
                                num.threads = 3, mtry = mtry[j], num.trees = numt[j])
    pred_cv[[i]] <- predict(ranger_lending_cv, data = test[[i]])$predictions

    results[[i]] <- bind_cols(truth = test[[i]]$loan_status, 
                              estimate=(as.numeric(pred_cv[[i]])-2)^2, 
                              f_estimate = pred_cv[[i]])
  
    metrics[[i]] <- results[[i]] %>% 
      metrics(truth = truth, estimate = f_estimate)
    kappa[i] <- metrics[[i]]$.estimate[2] 
    Acc[i] <- metrics[[i]]$.estimate[1]
  
    auc <- results[[i]] %>%
      roc_auc(truth = truth, estimate)
    AUC[i] <- auc$.estimate
  }
  mean_kappa[j] <- mean(kappa)
  mean_AUC[j] <- mean(AUC)
  mean_Acc[j] <- mean(Acc)
}  
output$mean_Acc <- mean_Acc
output$mean_AUC <- mean_AUC
output$mean_kappa <- mean_kappa
```

```{r}
output
```
























